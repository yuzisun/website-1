
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="KServe Documentation" name="description"/>
<link href="https://kserve.io/website/0.13/modelserving/v1beta1/triton/torchscript/" rel="canonical"/>
<link href="../../../../images/favicon/favicon-32x32.png" rel="icon"/>
<meta content="mkdocs-1.5.3, mkdocs-material-8.0.5" name="generator"/>
<title>Torchscript - KServe Documentation Website</title>
<link href="../../../../assets/stylesheets/main.a617204b.min.css" rel="stylesheet"/>
<link href="../../../../assets/stylesheets/palette.9204c3b2.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../../../stylesheets/extra.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
</head>
<body data-md-color-accent="none" data-md-color-primary="none" data-md-color-scheme="" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#predict-on-a-triton-inferenceservice-with-torchscript-model">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
<aside class="md-banner">
<div class="md-banner__inner md-grid md-typeset">
<h1>
<b>KServe v0.13 is Released</b>, <a href="/website/0.13/blog/articles/2024-05-15-KServe-0.13-release/">Read blog &gt;&gt;</a>
</h1>
</div>
</aside>
</div>
<div data-md-component="outdated" hidden="">
<aside class="md-banner md-banner--warning">
</aside>
</div>
<header class="md-header md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="KServe Documentation Website" class="md-header__button md-logo" data-md-component="logo" href="../../../.." title="KServe Documentation Website">
<img alt="logo" src="../../../../images/logo/kserve.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            KServe Documentation Website
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Torchscript
            
          </span>
</div>
</div>
</div>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/kserve/kserve" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-tabs__inner md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../..">
      Home
    </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../get_started/">
        Getting started
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../admin/serverless/serverless/">
        Administration Guide
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link md-tabs__link--active" href="../../../control_plane/">
        User Guide
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../reference/api/">
        API Reference
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../developer/developer/">
        Developer Guide
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../blog/articles/2023-10-08-KServe-0.13-release.md">
        Blog
      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../community/adopters/">
        Community
      </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="KServe Documentation Website" class="md-nav__button md-logo" data-md-component="logo" href="../../../.." title="KServe Documentation Website">
<img alt="logo" src="../../../../images/logo/kserve.png"/>
</a>
    KServe Documentation Website
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/kserve/kserve" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../..">
        Home
      </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" id="__nav_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2">
          Getting started
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Getting started" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
          Getting started
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../get_started/">
        KServe Quickstart
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../get_started/first_isvc/">
        First InferenceService
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../get_started/swagger_ui/">
        Interact with InferenceService Swagger UI
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3">
          Administration Guide
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Administration Guide" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
          Administration Guide
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1" id="__nav_3_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_1">
          Install KServe
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Install KServe" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_1">
<span class="md-nav__icon md-icon"></span>
          Install KServe
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_1_1" id="__nav_3_1_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_1_1">
          Serverless
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Serverless" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_3_1_1">
<span class="md-nav__icon md-icon"></span>
          Serverless
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../admin/serverless/serverless/">
        Serverless installation
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../admin/serverless/servicemesh/">
        Istio Service Mesh
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../admin/serverless/kourier_networking/">
        Kourier Networking Layer
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../admin/modelmesh/">
        ModelMesh installation
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../admin/kubernetes_deployment/">
        Kubernetes deployment installation
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../admin/migration/">
        Migrating from KFServing
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" id="__nav_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_4">
          User Guide
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="User Guide" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
          User Guide
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1" id="__nav_4_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_1">
          Concepts
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Concepts" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_1">
<span class="md-nav__icon md-icon"></span>
          Concepts
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_1" id="__nav_4_1_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_1_1">
          Control Plane
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Control Plane" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_4_1_1">
<span class="md-nav__icon md-icon"></span>
          Control Plane
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../control_plane/">
        Model Serving Control Plane
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_2" id="__nav_4_1_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_1_2">
          Data Plane
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Data Plane" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_4_1_2">
<span class="md-nav__icon md-icon"></span>
          Data Plane
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data_plane/data_plane/">
        Model Serving Data Plane
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data_plane/v1_protocol/">
        V1 Inference Protocol
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../data_plane/v2_protocol/">
        Open Inference Protocol (V2 Inference Protocol)
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../servingruntimes/">
        Serving Runtimes
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" id="__nav_4_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_2">
          Model Serving Runtimes
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Model Serving Runtimes" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_2">
<span class="md-nav__icon md-icon"></span>
          Model Serving Runtimes
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_1" id="__nav_4_2_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_2_1">
          Supported Model Frameworks/Formats
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Supported Model Frameworks/Formats" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_4_2_1">
<span class="md-nav__icon md-icon"></span>
          Supported Model Frameworks/Formats
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../serving_runtime/">
        Overview
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tensorflow/">
        Tensorflow
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../torchserve/">
        PyTorch
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../sklearn/v2/">
        Scikit-learn
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../xgboost/">
        XGBoost
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../pmml/">
        PMML
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../spark/">
        Spark MLlib
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../lightgbm/">
        LightGBM
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../paddle/">
        Paddle
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../mlflow/v2/">
        MLFlow
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../onnx/">
        ONNX
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_2" id="__nav_4_2_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_2_2">
          Multi-Framework Serving Runtimes
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Multi-Framework Serving Runtimes" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_4_2_2">
<span class="md-nav__icon md-icon"></span>
          Multi-Framework Serving Runtimes
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_2_1" id="__nav_4_2_2_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_2_2_1">
          Nvidia Triton
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Nvidia Triton" class="md-nav" data-md-level="4">
<label class="md-nav__title" for="__nav_4_2_2_1">
<span class="md-nav__icon md-icon"></span>
          Nvidia Triton
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
          Torchscript
          <span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
        Torchscript
      </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#setup">
    Setup
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#export-as-torchscript-model">
    Export as Torchscript Model
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#store-your-trained-model-on-cloud-storage-in-a-model-repository">
    Store your trained model on cloud storage in a Model Repository
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference-with-http-endpoint">
    Inference with HTTP endpoint
  </a>
<nav aria-label="Inference with HTTP endpoint" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#create-the-inferenceservice">
    Create the InferenceService
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#run-a-prediction-with-curl">
    Run a prediction with curl
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#run-a-performance-test">
    Run a performance test
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference-with-grpc-endpoint">
    Inference with gRPC endpoint
  </a>
<nav aria-label="Inference with gRPC endpoint" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#create-the-inferenceservice_1">
    Create the InferenceService
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#run-a-prediction-with-grpcurl">
    Run a prediction with grpcurl
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#add-transformer-to-the-inferenceservice">
    Add Transformer to the InferenceService
  </a>
<nav aria-label="Add Transformer to the InferenceService" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#implement-prepost-processing-functions">
    Implement pre/post processing functions
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#build-transformer-docker-image">
    Build Transformer docker image
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#create-the-inferenceservice-with-transformer">
    Create the InferenceService with Transformer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#run-a-prediction-with-curl_1">
    Run a prediction with curl
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../bert/">
        Tensorflow
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../huggingface/">
        Hugging Face
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../amd/">
        AMD
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_3" id="__nav_4_2_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_2_3">
          LLM Runtime
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="LLM Runtime" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_4_2_3">
<span class="md-nav__icon md-icon"></span>
          LLM Runtime
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../llm/huggingface/">
        Hugging Face LLM
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../llm/torchserve/accelerate/">
        TorchServe LLM
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../custom/custom_model/">
        How to write a custom predictor
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" id="__nav_4_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_3">
          Multi Model Serving
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Multi Model Serving" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_3">
<span class="md-nav__icon md-icon"></span>
          Multi Model Serving
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_1" id="__nav_4_3_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_3_1">
          Overview
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Overview" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_4_3_1">
<span class="md-nav__icon md-icon"></span>
          Overview
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../mms/multi-model-serving/">
        The Scalability Problem
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../mms/modelmesh/overview/">
        ModelMesh Overview
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_4" id="__nav_4_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_4">
          Transformers
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Transformers" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_4">
<span class="md-nav__icon md-icon"></span>
          Transformers
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../transformer/feast/">
        Feast
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../transformer/torchserve_image_transformer/">
        How to write a custom transformer
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../transformer/collocation/">
        Collocate transformer and predictor
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_5" id="__nav_4_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_5">
          Inference Graph
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Inference Graph" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_5">
<span class="md-nav__icon md-icon"></span>
          Inference Graph
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../inference_graph/">
        Concept
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../inference_graph/image_pipeline/">
        Image classification inference graph
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_6" id="__nav_4_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_6">
          Model Storage
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Model Storage" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_6">
<span class="md-nav__icon md-icon"></span>
          Model Storage
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../storage/storagecontainers/">
        Storage Containers
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../storage/azure/azure/">
        Azure
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../storage/pvc/pvc/">
        PVC
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../storage/s3/s3/">
        S3
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../storage/oci/">
        OCI
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../storage/uri/uri/">
        URI
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../certificate/kserve/">
        CA Certificate
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../storage/gcs/gcs/">
        GCS
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_7" id="__nav_4_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_7">
          Model Explainability
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Model Explainability" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_7">
<span class="md-nav__icon md-icon"></span>
          Model Explainability
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../explainer/explainer/">
        Concept
      </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_7_2" id="__nav_4_7_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_7_2">
          Alibi Explainer
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Alibi Explainer" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_4_7_2">
<span class="md-nav__icon md-icon"></span>
          Alibi Explainer
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../explainer/alibi/cifar10/">
        Image Explainer
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../explainer/alibi/income/">
        Income Explainer
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../explainer/alibi/moviesentiment/">
        Text Explainer
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../explainer/aix/mnist/aix/">
        AIX Explainer
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_8" id="__nav_4_8" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_8">
          Model Monitoring
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Model Monitoring" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_8">
<span class="md-nav__icon md-icon"></span>
          Model Monitoring
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../detect/alibi_detect/alibi_detect/">
        Alibi Detector
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../detect/aif/germancredit/">
        AIF Bias Detector
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../detect/art/mnist/">
        ART Adversarial Detector
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_9" id="__nav_4_9" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_9">
          Request Batching
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Request Batching" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_9">
<span class="md-nav__icon md-icon"></span>
          Request Batching
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../batcher/batcher/">
        Inference Batcher
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_10" id="__nav_4_10" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_10">
          Payload Logging
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Payload Logging" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_10">
<span class="md-nav__icon md-icon"></span>
          Payload Logging
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../logger/logger/">
        Inference Logger
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_11" id="__nav_4_11" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_11">
          Autoscaling
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Autoscaling" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_11">
<span class="md-nav__icon md-icon"></span>
          Autoscaling
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../autoscaling/autoscaling/">
        Inference Autoscaling
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_12" id="__nav_4_12" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_12">
          Node Scheduling
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Node Scheduling" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_12">
<span class="md-nav__icon md-icon"></span>
          Node Scheduling
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../nodescheduling/overview/">
        Overview
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../nodescheduling/inferenceservicenodescheduling/">
        InferenceService Node Scheduling
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_13" id="__nav_4_13" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_13">
          Kafka
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Kafka" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_13">
<span class="md-nav__icon md-icon"></span>
          Kafka
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../kafka/kafka/">
        Inference with Kafka event source
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_14" id="__nav_4_14" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_14">
          Rollout Strategies
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Rollout Strategies" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_14">
<span class="md-nav__icon md-icon"></span>
          Rollout Strategies
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../rollout/canary/">
        Canary
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../rollout/canary-example/">
        Canary Example
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_15" id="__nav_4_15" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_15">
          Inference Observability
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Inference Observability" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_15">
<span class="md-nav__icon md-icon"></span>
          Inference Observability
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../observability/prometheus_metrics/">
        Prometheus Metrics
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../observability/grafana_dashboards/">
        Grafana Dashboards
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" id="__nav_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_5">
          API Reference
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="API Reference" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_5">
<span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../reference/api/">
        Control Plane API
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../reference/swagger-ui/">
        Open Inference Protocol API Spec
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../sdk_docs/sdk_doc/">
        Python Client SDK
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../python_runtime_api/docs/">
        Python Runtime Server SDK
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" id="__nav_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_6">
          Developer Guide
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Developer Guide" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
          Developer Guide
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../developer/developer/">
        How to contribute
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../developer/debug/">
        Debugging guide
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" id="__nav_7" type="checkbox"/>
<label class="md-nav__link" for="__nav_7">
          Blog
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Blog" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_7">
<span class="md-nav__icon md-icon"></span>
          Blog
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_1" id="__nav_7_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_1">
          Releases
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Releases" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_1">
<span class="md-nav__icon md-icon"></span>
          Releases
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../blog/articles/2023-10-08-KServe-0.13-release.md">
        KServe 0.13 Release
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../blog/articles/2023-10-08-KServe-0.11-release/">
        KServe 0.11 Release
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../blog/articles/2023-02-05-KServe-0.10-release/">
        KServe 0.10 Release
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../blog/articles/2022-07-21-KServe-0.9-release/">
        KServe 0.9 Release
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../blog/articles/2022-02-18-KServe-0.8-release/">
        KServe 0.8 Release
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../blog/articles/2021-10-11-KServe-0.7-release/">
        KServe 0.7 Release
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_2" id="__nav_7_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_7_2">
          Articles
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Articles" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_7_2">
<span class="md-nav__icon md-icon"></span>
          Articles
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../blog/articles/2021-09-27-kfserving-transition/">
        KFserving Transition
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_8" id="__nav_8" type="checkbox"/>
<label class="md-nav__link" for="__nav_8">
          Community
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Community" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_8">
<span class="md-nav__icon md-icon"></span>
          Community
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../community/adopters/">
        Adopters
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../../community/presentations/">
        Demos and Presentations
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#setup">
    Setup
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#export-as-torchscript-model">
    Export as Torchscript Model
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#store-your-trained-model-on-cloud-storage-in-a-model-repository">
    Store your trained model on cloud storage in a Model Repository
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference-with-http-endpoint">
    Inference with HTTP endpoint
  </a>
<nav aria-label="Inference with HTTP endpoint" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#create-the-inferenceservice">
    Create the InferenceService
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#run-a-prediction-with-curl">
    Run a prediction with curl
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#run-a-performance-test">
    Run a performance test
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#inference-with-grpc-endpoint">
    Inference with gRPC endpoint
  </a>
<nav aria-label="Inference with gRPC endpoint" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#create-the-inferenceservice_1">
    Create the InferenceService
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#run-a-prediction-with-grpcurl">
    Run a prediction with grpcurl
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#add-transformer-to-the-inferenceservice">
    Add Transformer to the InferenceService
  </a>
<nav aria-label="Add Transformer to the InferenceService" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#implement-prepost-processing-functions">
    Implement pre/post processing functions
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#build-transformer-docker-image">
    Build Transformer docker image
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#create-the-inferenceservice-with-transformer">
    Create the InferenceService with Transformer
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#run-a-prediction-with-curl_1">
    Run a prediction with curl
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/kserve/website/edit/main/docs/modelserving/v1beta1/triton/torchscript/README.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
</a>
<h1 id="predict-on-a-triton-inferenceservice-with-torchscript-model">Predict on a Triton InferenceService with TorchScript model<a class="headerlink" href="#predict-on-a-triton-inferenceservice-with-torchscript-model" title="Permanent link">¶</a></h1>
<p>While Python is a suitable and preferred language for many scenarios requiring dynamism and ease of iteration,
there are equally many situations where precisely these properties of Python are unfavorable. One environment in which
the latter often applies is production – the land of low latencies and strict deployment requirements. For production scenarios,
C++ is very often the language of choice, The following example will outline the path PyTorch provides to go from an existing Python model
to a serialized representation that can be loaded and executed purely from C++ like Triton Inference Server, with no dependency on Python.</p>
<h2 id="setup">Setup<a class="headerlink" href="#setup" title="Permanent link">¶</a></h2>
<ol>
<li>Make sure you have installed <a href="https://kserve.github.io/website/get_started/#install-the-kserve-quickstart-environment">KServe</a></li>
<li>Skip <a href="https://knative.dev/docs/serving/tag-resolution/">tag resolution</a> for <code>nvcr.io</code> which requires auth to resolve triton inference server image digest
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>patch<span class="w"> </span>cm<span class="w"> </span>config-deployment<span class="w"> </span>--patch<span class="w"> </span><span class="s1">'{"data":{"registriesSkippingTagResolving":"nvcr.io"}}'</span><span class="w"> </span>-n<span class="w"> </span>knative-serving
</code></pre></div></li>
<li>Increase progress deadline since pulling triton image and big bert model may longer than default timeout for 120s, this setting requires knative 0.15.0+
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>patch<span class="w"> </span>cm<span class="w"> </span>config-deployment<span class="w"> </span>--patch<span class="w"> </span><span class="s1">'{"data":{"progressDeadline": "600s"}}'</span><span class="w"> </span>-n<span class="w"> </span>knative-serving
</code></pre></div></li>
</ol>
<h2 id="export-as-torchscript-model">Export as Torchscript Model<a class="headerlink" href="#export-as-torchscript-model" title="Permanent link">¶</a></h2>
<p>A PyTorch model’s journey from Python to C++ is enabled by <a href="https://pytorch.org/docs/master/jit.html">Torch Script</a>, a representation of a PyTorch model
that can be understood, compiled and serialized by the Torch Script compiler. If you are starting out from an existing PyTorch model written in the vanilla <code>eager</code> API,
you must first convert your model to Torch Script.</p>
<p>Convert the above model via Tracing and serialize the script module to a file
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1"># Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.</span>
<span class="n">example</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="n">traced_script_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">example</span><span class="p">)</span>
<span class="n">traced_script_module</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"model.pt"</span><span class="p">)</span>
</code></pre></div></p>
<h2 id="store-your-trained-model-on-cloud-storage-in-a-model-repository">Store your trained model on cloud storage in a Model Repository<a class="headerlink" href="#store-your-trained-model-on-cloud-storage-in-a-model-repository" title="Permanent link">¶</a></h2>
<p>Once the model is exported as <code>TorchScript</code> model file, the next step is to upload the model to a GCS bucket.
Triton supports loading multiple models so it expects a model repository which follows a required layout in the bucket.
<div class="highlight"><pre><span></span><code>&lt;model-repository-path&gt;/
  &lt;model-name&gt;/
    [config.pbtxt]
    [&lt;output-labels-file&gt; ...]
    &lt;version&gt;/
      &lt;model-definition-file&gt;
    &lt;version&gt;/
      &lt;model-definition-file&gt;
    ...
  &lt;model-name&gt;/
    [config.pbtxt]
    [&lt;output-labels-file&gt; ...]
    &lt;version&gt;/
      &lt;model-definition-file&gt;
    &lt;version&gt;/
      &lt;model-definition-file&gt;
</code></pre></div>
For example in your model repository bucket <code>gs://kfserving-examples/models/torchscript</code>, the layout can be
<div class="highlight"><pre><span></span><code>torchscript/
  cifar/
    config.pbtxt
    1/
      model.pt
</code></pre></div>
The config.pbtxt defines a model configuration that provides the required and optional information for the model.
A minimal model configuration must specify name, platform, max_batch_size, input, and output. Due to the absence of names
for inputs and outputs in a TorchScript model, the <code>name</code> attribute of both the inputs and outputs in the configuration must
follow a specific naming convention i.e. “<name>__<index>”. Where <name> can be any string and <index> refers to the position of the corresponding
input/output. This means if there are two inputs and two outputs they must be named as: <code>INPUT__0</code>, <code>INPUT__1</code> and <code>OUTPUT__0</code>, <code>OUTPUT__1</code> such that <code>INPUT__0</code>
refers to first input and INPUT__1 refers to the second input, etc.
<div class="highlight"><pre><span></span><code><span class="kc">na</span><span class="err">me</span><span class="p">:</span><span class="w"> </span><span class="s2">"cifar"</span>
<span class="err">pla</span><span class="kc">tf</span><span class="err">orm</span><span class="p">:</span><span class="w"> </span><span class="s2">"pytorch_libtorch"</span>
<span class="err">max_ba</span><span class="kc">t</span><span class="err">ch_size</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="err">i</span><span class="kc">n</span><span class="err">pu</span><span class="kc">t</span><span class="w"> </span><span class="p">[</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kc">na</span><span class="err">me</span><span class="p">:</span><span class="w"> </span><span class="s2">"INPUT__0"</span>
<span class="w">    </span><span class="err">da</span><span class="kc">ta</span><span class="err">_</span><span class="kc">t</span><span class="err">ype</span><span class="p">:</span><span class="w"> </span><span class="err">TYPE_FP</span><span class="mi">32</span>
<span class="w">    </span><span class="err">dims</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">]</span>
<span class="err">ou</span><span class="kc">t</span><span class="err">pu</span><span class="kc">t</span><span class="w"> </span><span class="p">[</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="kc">na</span><span class="err">me</span><span class="p">:</span><span class="w"> </span><span class="s2">"OUTPUT__0"</span>
<span class="w">    </span><span class="err">da</span><span class="kc">ta</span><span class="err">_</span><span class="kc">t</span><span class="err">ype</span><span class="p">:</span><span class="w"> </span><span class="err">TYPE_FP</span><span class="mi">32</span>
<span class="w">    </span><span class="err">dims</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">10</span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">]</span>

<span class="err">i</span><span class="kc">nstan</span><span class="err">ce_group</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="err">cou</span><span class="kc">nt</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">        </span><span class="err">ki</span><span class="kc">n</span><span class="err">d</span><span class="p">:</span><span class="w"> </span><span class="err">KIND_CPU</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">]</span>
</code></pre></div></index></name></index></name></p>
<p><code>instance_group</code> provides multiple instances of a model so that multiple inference requests for that model can be
handled simultaneously.
<div class="highlight"><pre><span></span><code>instance_group [
    {
      count: 4
      kind: KIND_CPU
    }
  ]
</code></pre></div></p>
<p>To schedule the model on GPU you would need to change the <code>instance_group</code> with GPU kind
<div class="highlight"><pre><span></span><code>instance_group [
    {
        count: 1
        kind: KIND_GPU
    }
]
</code></pre></div>
For more details, please refer to <a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_configuration.html">triton model configuration</a>.</p>
<h2 id="inference-with-http-endpoint">Inference with HTTP endpoint<a class="headerlink" href="#inference-with-http-endpoint" title="Permanent link">¶</a></h2>
<h3 id="create-the-inferenceservice">Create the InferenceService<a class="headerlink" href="#create-the-inferenceservice" title="Permanent link">¶</a></h3>
<p>Create the inference service yaml with the above specified model repository uri.</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">serving.kserve.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">InferenceService</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torchscript-cifar10</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">predictor</span><span class="p">:</span>
<span class="w">    </span><span class="nt">triton</span><span class="p">:</span>
<span class="w">      </span><span class="nt">storageUri</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gs://kfserving-examples/models/torchscript</span>
<span class="w">      </span><span class="nt">runtimeVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20.10-py3</span>
<span class="w">      </span><span class="nt">env</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">OMP_NUM_THREADS</span>
<span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">"1"</span>
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Setting OMP_NUM_THREADS or MKL_NUM_THREADS envs are critical for performance, these environment variables are used
to control the intra-op parallelism for TorchScript model inference, the number of CPU threads defaults to the number of CPU cores.
Please refer to <a href="https://pytorch.org/docs/stable/notes/cpu_threading_torchscript_inference.html">CPU threading &amp; TorchScript Inference</a> for more details.</p>
</div>
<div class="tabbed-set tabbed-alternate" data-tabs="1:1"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio"><div class="tabbed-labels"><label for="__tabbed_1_1">kubectl</label></div>
<div class="tabbed-content">
<div class="tabbed-block"></div>
</div>
</input></div>
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>torchscript.yaml
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>$<span class="w"> </span>inferenceservice.serving.kserve.io/torchscript-cifar10<span class="w"> </span>created
</code></pre></div>
</div>
<h3 id="run-a-prediction-with-curl">Run a prediction with curl<a class="headerlink" href="#run-a-prediction-with-curl" title="Permanent link">¶</a></h3>
<p>The first step is to <a href="https://kserve.github.io/website/get_started/first_isvc/#4-determine-the-ingress-ip-and-ports">determine the ingress IP and ports</a> and set <code>INGRESS_HOST</code> and <code>INGRESS_PORT</code></p>
<p>The latest Triton Inference Server already switched to use KServe <a href="https://github.com/kserve/kserve/tree/master/docs/predict-api/v2">prediction V2 protocol</a>, so
the input request needs to follow the V2 schema with the specified data type, shape.
<div class="highlight"><pre><span></span><code><span class="c1"># download the input file</span>
curl<span class="w"> </span>-O<span class="w"> </span>https://raw.githubusercontent.com/kserve/kserve/master/docs/samples/v1beta1/triton/torchscript/input.json

<span class="nv">MODEL_NAME</span><span class="o">=</span>cifar10
<span class="nv">INPUT_PATH</span><span class="o">=</span>@./input.json
<span class="nv">SERVICE_HOSTNAME</span><span class="o">=</span><span class="k">$(</span>kubectl<span class="w"> </span>get<span class="w"> </span>inferenceservice<span class="w"> </span>torchscript-cifar10<span class="w"> </span>-o<span class="w"> </span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.url}'</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>cut<span class="w"> </span>-d<span class="w"> </span><span class="s2">"/"</span><span class="w"> </span>-f<span class="w"> </span><span class="m">3</span><span class="k">)</span>
curl<span class="w"> </span>-v<span class="w"> </span>-H<span class="w"> </span><span class="s2">"Host: </span><span class="si">${</span><span class="nv">SERVICE_HOSTNAME</span><span class="si">}</span><span class="s2">"</span><span class="w"> </span>-H<span class="w"> </span><span class="s2">"Content-Type: application/json"</span><span class="w"> </span>http://<span class="si">${</span><span class="nv">INGRESS_HOST</span><span class="si">}</span>:<span class="si">${</span><span class="nv">INGRESS_PORT</span><span class="si">}</span>/v2/models/<span class="si">${</span><span class="nv">MODEL_NAME</span><span class="si">}</span>/infer<span class="w"> </span>-d<span class="w"> </span><span class="nv">$INPUT_PATH</span>
</code></pre></div></p>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>*<span class="w"> </span>Connected<span class="w"> </span>to<span class="w"> </span>torchscript-cifar.default.svc.cluster.local<span class="w"> </span><span class="o">(</span><span class="m">10</span>.51.242.87<span class="o">)</span><span class="w"> </span>port<span class="w"> </span><span class="m">80</span><span class="w"> </span><span class="o">(</span><span class="c1">#0)</span>
&gt;<span class="w"> </span>POST<span class="w"> </span>/v2/models/cifar10/infer<span class="w"> </span>HTTP/1.1
&gt;<span class="w"> </span>Host:<span class="w"> </span>torchscript-cifar.default.svc.cluster.local
&gt;<span class="w"> </span>User-Agent:<span class="w"> </span>curl/7.47.0
&gt;<span class="w"> </span>Accept:<span class="w"> </span>*/*
&gt;<span class="w"> </span>Content-Length:<span class="w"> </span><span class="m">110765</span>
&gt;<span class="w"> </span>Content-Type:<span class="w"> </span>application/x-www-form-urlencoded
&gt;<span class="w"> </span>Expect:<span class="w"> </span><span class="m">100</span>-continue
&gt;
&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">100</span><span class="w"> </span>Continue
*<span class="w"> </span>We<span class="w"> </span>are<span class="w"> </span>completely<span class="w"> </span>uploaded<span class="w"> </span>and<span class="w"> </span>fine
&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">200</span><span class="w"> </span>OK
&lt;<span class="w"> </span>content-length:<span class="w"> </span><span class="m">315</span>
&lt;<span class="w"> </span>content-type:<span class="w"> </span>application/json
&lt;<span class="w"> </span>date:<span class="w"> </span>Sun,<span class="w"> </span><span class="m">11</span><span class="w"> </span>Oct<span class="w"> </span><span class="m">2020</span><span class="w"> </span><span class="m">21</span>:26:51<span class="w"> </span>GMT
&lt;<span class="w"> </span>x-envoy-upstream-service-time:<span class="w"> </span><span class="m">8</span>
&lt;<span class="w"> </span>server:<span class="w"> </span>istio-envoy
&lt;
*<span class="w"> </span>Connection<span class="w"> </span><span class="c1">#0 to host torchscript-cifar.default.svc.cluster.local left intact</span>
<span class="o">{</span><span class="s2">"model_name"</span>:<span class="s2">"cifar10"</span>,<span class="s2">"model_version"</span>:<span class="s2">"1"</span>,<span class="s2">"outputs"</span>:<span class="o">[{</span><span class="s2">"name"</span>:<span class="s2">"OUTPUT__0"</span>,<span class="s2">"datatype"</span>:<span class="s2">"FP32"</span>,<span class="s2">"shape"</span>:<span class="o">[</span><span class="m">1</span>,10<span class="o">]</span>,<span class="s2">"data"</span>:<span class="o">[</span>-2.0964810848236086,-0.13700756430625916,-0.5095657706260681,2.795621395111084,-0.5605481863021851,1.9934231042861939,1.1288187503814698,-1.4043136835098267,0.6004879474639893,-2.1237082481384279<span class="o">]}]}</span>
</code></pre></div>
</div>
<h3 id="run-a-performance-test">Run a performance test<a class="headerlink" href="#run-a-performance-test" title="Permanent link">¶</a></h3>
<p>QPS rate <code>--rate</code> can be changed in the <a href="perf.yaml">perf.yaml</a>.
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span>perf.yaml

Requests<span class="w">      </span><span class="o">[</span>total,<span class="w"> </span>rate,<span class="w"> </span>throughput<span class="o">]</span><span class="w">         </span><span class="m">6000</span>,<span class="w"> </span><span class="m">100</span>.02,<span class="w"> </span><span class="m">100</span>.01
Duration<span class="w">      </span><span class="o">[</span>total,<span class="w"> </span>attack,<span class="w"> </span>wait<span class="o">]</span><span class="w">             </span><span class="m">59</span>.995s,<span class="w"> </span><span class="m">59</span>.99s,<span class="w"> </span><span class="m">4</span>.961ms
Latencies<span class="w">     </span><span class="o">[</span>min,<span class="w"> </span>mean,<span class="w"> </span><span class="m">50</span>,<span class="w"> </span><span class="m">90</span>,<span class="w"> </span><span class="m">95</span>,<span class="w"> </span><span class="m">99</span>,<span class="w"> </span>max<span class="o">]</span><span class="w">  </span><span class="m">4</span>.222ms,<span class="w"> </span><span class="m">5</span>.7ms,<span class="w"> </span><span class="m">5</span>.548ms,<span class="w"> </span><span class="m">6</span>.384ms,<span class="w"> </span><span class="m">6</span>.743ms,<span class="w"> </span><span class="m">9</span>.286ms,<span class="w"> </span><span class="m">25</span>.85ms
Bytes<span class="w"> </span>In<span class="w">      </span><span class="o">[</span>total,<span class="w"> </span>mean<span class="o">]</span><span class="w">                     </span><span class="m">1890000</span>,<span class="w"> </span><span class="m">315</span>.00
Bytes<span class="w"> </span>Out<span class="w">     </span><span class="o">[</span>total,<span class="w"> </span>mean<span class="o">]</span><span class="w">                     </span><span class="m">665874000</span>,<span class="w"> </span><span class="m">110979</span>.00
Success<span class="w">       </span><span class="o">[</span>ratio<span class="o">]</span><span class="w">                           </span><span class="m">100</span>.00%
Status<span class="w"> </span>Codes<span class="w">  </span><span class="o">[</span>code:count<span class="o">]</span><span class="w">                      </span><span class="m">200</span>:6000
Error<span class="w"> </span>Set:
</code></pre></div></p>
<h2 id="inference-with-grpc-endpoint">Inference with gRPC endpoint<a class="headerlink" href="#inference-with-grpc-endpoint" title="Permanent link">¶</a></h2>
<h3 id="create-the-inferenceservice_1">Create the InferenceService<a class="headerlink" href="#create-the-inferenceservice_1" title="Permanent link">¶</a></h3>
<p>Create the inference service yaml and expose the gRPC port, currently only one port is allowed to expose either HTTP or gRPC port and by default HTTP port is exposed.</p>
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">serving.kserve.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">InferenceService</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torchscript-cifar10</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">predictor</span><span class="p">:</span>
<span class="w">    </span><span class="nt">triton</span><span class="p">:</span>
<span class="w">      </span><span class="nt">storageUri</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gs://kfserving-examples/models/torchscript</span>
<span class="w">      </span><span class="nt">runtimeVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20.10-py3</span>
<span class="w">      </span><span class="nt">ports</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">9000</span>
<span class="w">        </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">h2c</span>
<span class="w">        </span><span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TCP</span>
<span class="w">      </span><span class="nt">env</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">OMP_NUM_THREADS</span>
<span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">"1"</span>
</code></pre></div>
<p>Apply the gRPC <code>InferenceService</code> yaml and then you can call the model with <code>tritonclient</code> python library after <code>InferenceService</code> is ready.
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>torchscript_grpc.yaml
</code></pre></div></p>
<h3 id="run-a-prediction-with-grpcurl">Run a prediction with grpcurl<a class="headerlink" href="#run-a-prediction-with-grpcurl" title="Permanent link">¶</a></h3>
<p>After the gRPC <code>InferenceService</code> becomes ready, <a href="https://github.com/fullstorydev/grpcurl">grpcurl</a>, can be used to send gRPC requests to the <code>InferenceService</code>.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># download the proto file</span>
curl<span class="w"> </span>-O<span class="w"> </span>https://raw.githubusercontent.com/kserve/kserve/master/docs/predict-api/v2/grpc_predict_v2.proto

<span class="c1"># download the input json file</span>
curl<span class="w"> </span>-O<span class="w"> </span>https://raw.githubusercontent.com/kserve/website/main/docs/modelserving/v1beta1/triton/torchscript/input-grpc.json

<span class="nv">INPUT_PATH</span><span class="o">=</span>input-grpc.json
<span class="nv">PROTO_FILE</span><span class="o">=</span>grpc_predict_v2.proto
<span class="nv">SERVICE_HOSTNAME</span><span class="o">=</span><span class="k">$(</span>kubectl<span class="w"> </span>get<span class="w"> </span>inferenceservice<span class="w"> </span>torchscript-cifar10<span class="w"> </span>-o<span class="w"> </span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.url}'</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>cut<span class="w"> </span>-d<span class="w"> </span><span class="s2">"/"</span><span class="w"> </span>-f<span class="w"> </span><span class="m">3</span><span class="k">)</span>
</code></pre></div>
<p>The gRPC APIs follow the KServe <a href="https://github.com/kserve/kserve/tree/master/docs/predict-api/v2">prediction V2 protocol</a>.</p>
<p>For example, <code>ServerReady</code> API can be used to check if the server is ready:</p>
<div class="highlight"><pre><span></span><code>grpcurl<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-plaintext<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-proto<span class="w"> </span><span class="si">${</span><span class="nv">PROTO_FILE</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-authority<span class="w"> </span><span class="si">${</span><span class="nv">SERVICE_HOSTNAME</span><span class="si">}</span><span class="s2">" \</span>
<span class="s2">  </span><span class="si">${</span><span class="nv">INGRESS_HOST</span><span class="si">}</span><span class="s2">:</span><span class="si">${</span><span class="nv">INGRESS_PORT</span><span class="si">}</span><span class="s2"> \</span>
<span class="s2">  inference.GRPCInferenceService.ServerReady</span>
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">"ready"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="p">}</span>
</code></pre></div>
</div>
<p><code>ModelInfer</code> API takes input following the <code>ModelInferRequest</code> schema defined in the <code>grpc_predict_v2.proto</code> file. Notice that the input file differs from that used in the previous <code>curl</code> example. </p>
<div class="highlight"><pre><span></span><code>grpcurl<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-vv<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-plaintext<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-proto<span class="w"> </span><span class="si">${</span><span class="nv">PROTO_FILE</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s2">"Host: </span><span class="si">${</span><span class="nv">SERVICE_HOSTNAME</span><span class="si">}</span><span class="s2">"</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span>@<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="si">${</span><span class="nv">INGRESS_HOST</span><span class="si">}</span>:<span class="si">${</span><span class="nv">INGRESS_PORT</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>inference.GRPCInferenceService.ModelInfer<span class="w"> </span><span class="se">\</span>
<span class="w">  </span><span class="o">&lt;&lt;&lt;</span><span class="w"> </span><span class="k">$(</span>cat<span class="w"> </span><span class="s2">"</span><span class="nv">$INPUT_PATH</span><span class="s2">"</span><span class="k">)</span>
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>Resolved<span class="w"> </span>method<span class="w"> </span>descriptor:
//<span class="w"> </span>The<span class="w"> </span>ModelInfer<span class="w"> </span>API<span class="w"> </span>performs<span class="w"> </span>inference<span class="w"> </span>using<span class="w"> </span>the<span class="w"> </span>specified<span class="w"> </span>model.<span class="w"> </span>Errors<span class="w"> </span>are
//<span class="w"> </span>indicated<span class="w"> </span>by<span class="w"> </span>the<span class="w"> </span>google.rpc.Status<span class="w"> </span>returned<span class="w"> </span><span class="k">for</span><span class="w"> </span>the<span class="w"> </span>request.<span class="w"> </span>The<span class="w"> </span>OK<span class="w"> </span>code
//<span class="w"> </span>indicates<span class="w"> </span>success<span class="w"> </span>and<span class="w"> </span>other<span class="w"> </span>codes<span class="w"> </span>indicate<span class="w"> </span>failure.
rpc<span class="w"> </span>ModelInfer<span class="w"> </span><span class="o">(</span><span class="w"> </span>.inference.ModelInferRequest<span class="w"> </span><span class="o">)</span><span class="w"> </span>returns<span class="w"> </span><span class="o">(</span><span class="w"> </span>.inference.ModelInferResponse<span class="w"> </span><span class="o">)</span><span class="p">;</span>

Request<span class="w"> </span>metadata<span class="w"> </span>to<span class="w"> </span>send:
host:<span class="w"> </span>torchscript-cifar10.default.example.com

Response<span class="w"> </span>headers<span class="w"> </span>received:
accept-encoding:<span class="w"> </span>identity,gzip
content-type:<span class="w"> </span>application/grpc
date:<span class="w"> </span>Fri,<span class="w"> </span><span class="m">12</span><span class="w"> </span>Aug<span class="w"> </span><span class="m">2022</span><span class="w"> </span><span class="m">01</span>:49:53<span class="w"> </span>GMT
grpc-accept-encoding:<span class="w"> </span>identity,deflate,gzip
server:<span class="w"> </span>istio-envoy
x-envoy-upstream-service-time:<span class="w"> </span><span class="m">16</span>

Response<span class="w"> </span>contents:
<span class="o">{</span>
<span class="w">  </span><span class="s2">"modelName"</span>:<span class="w"> </span><span class="s2">"cifar10"</span>,
<span class="w">  </span><span class="s2">"modelVersion"</span>:<span class="w"> </span><span class="s2">"1"</span>,
<span class="w">  </span><span class="s2">"outputs"</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">    </span><span class="o">{</span>
<span class="w">      </span><span class="s2">"name"</span>:<span class="w"> </span><span class="s2">"OUTPUT__0"</span>,
<span class="w">      </span><span class="s2">"datatype"</span>:<span class="w"> </span><span class="s2">"FP32"</span>,
<span class="w">      </span><span class="s2">"shape"</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">        </span><span class="s2">"1"</span>,
<span class="w">        </span><span class="s2">"10"</span>
<span class="w">      </span><span class="o">]</span>
<span class="w">    </span><span class="o">}</span>
<span class="w">  </span><span class="o">]</span>,
<span class="w">  </span><span class="s2">"rawOutputContents"</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">    </span><span class="s2">"wCwGwOJLDL7icgK/dusyQAqAD799KP8/In2QP4zAs7+WuRk/2OoHwA=="</span>
<span class="w">  </span><span class="o">]</span>
<span class="o">}</span>

Response<span class="w"> </span>trailers<span class="w"> </span>received:
<span class="o">(</span>empty<span class="o">)</span>
Sent<span class="w"> </span><span class="m">1</span><span class="w"> </span>request<span class="w"> </span>and<span class="w"> </span>received<span class="w"> </span><span class="m">1</span><span class="w"> </span>response
</code></pre></div>
</div>
<p>The content of output tensor is encoded in <code>rawOutputContents</code> field. It can be <code>base64</code> decoded and loaded into a Numpy array with the given datatype and shape.</p>
<p>Alternatively, Triton also provides <a href="https://pypi.org/project/tritonclient/">Python client library</a> which has many <a href="https://github.com/triton-inference-server/client/tree/main/src/python/examples">examples</a> showing how to interact with the KServe V2 gPRC protocol.</p>
<h2 id="add-transformer-to-the-inferenceservice">Add Transformer to the InferenceService<a class="headerlink" href="#add-transformer-to-the-inferenceservice" title="Permanent link">¶</a></h2>
<p><code>Triton Inference Server</code> expects tensors as input data, often times a pre-processing step is required before making the prediction call
when the user is sending in request with raw input format. Transformer component can be specified on InferenceService spec for user implemented pre/post processing code.
User is responsible to create a python class which extends from KServe <code>Model</code> base class which implements <code>preprocess</code> handler to transform raw input
format to tensor format according to V2 prediction protocol, <code>postprocess</code> handle is to convert raw prediction response to a more user friendly response.</p>
<h3 id="implement-prepost-processing-functions">Implement pre/post processing functions<a class="headerlink" href="#implement-prepost-processing-functions" title="Permanent link">¶</a></h3>
<p><div class="highlight"><span class="filename">image_transformer_v2.py</span><pre><span></span><code><span class="kn">import</span> <span class="nn">kserve</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">base64</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">kserve</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">KSERVE_LOGLEVEL</span><span class="p">)</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
         <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))])</span>

<span class="k">def</span> <span class="nf">image_transform</span><span class="p">(</span><span class="n">instance</span><span class="p">):</span>
    <span class="n">byte_array</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">instance</span><span class="p">[</span><span class="s1">'image_bytes'</span><span class="p">][</span><span class="s1">'b64'</span><span class="p">])</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">byte_array</span><span class="p">))</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">ImageTransformerV2</span><span class="p">(</span><span class="n">kserve</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">predictor_host</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">protocol</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictor_host</span> <span class="o">=</span> <span class="n">predictor_host</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">protocol</span> <span class="o">=</span> <span class="n">protocol</span>

    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span>
           <span class="s1">'inputs'</span><span class="p">:</span> <span class="p">[</span>
               <span class="p">{</span>
                 <span class="s1">'name'</span><span class="p">:</span> <span class="s1">'INPUT__0'</span><span class="p">,</span>
                 <span class="s1">'shape'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
                 <span class="s1">'datatype'</span><span class="p">:</span> <span class="s2">"FP32"</span><span class="p">,</span>
                 <span class="s1">'data'</span><span class="p">:</span> <span class="p">[</span><span class="n">image_transform</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span> <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">[</span><span class="s1">'instances'</span><span class="p">]]</span>
               <span class="p">}</span>
            <span class="p">]</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">postprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">output</span><span class="p">[</span><span class="s2">"name"</span><span class="p">]:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s2">"data"</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s2">"shape"</span><span class="p">])</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="s2">"outputs"</span><span class="p">]}</span>
</code></pre></div>
Please find <a href="https://github.com/kserve/kserve/tree/release-0.10/docs/samples/v1beta1/triton/torchscript/image_transformer_v2">the code example</a> and <a href="https://github.com/kserve/kserve/blob/release-0.10/docs/samples/v1beta1/triton/torchscript/transformer.Dockerfile">Dockerfile</a>.</p>
<h3 id="build-transformer-docker-image">Build Transformer docker image<a class="headerlink" href="#build-transformer-docker-image" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code>docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span><span class="nv">$DOCKER_USER</span>/image-transformer-v2:latest<span class="w"> </span>-f<span class="w"> </span>transformer.Dockerfile<span class="w"> </span>.<span class="w"> </span>--rm
</code></pre></div>
<h3 id="create-the-inferenceservice-with-transformer">Create the InferenceService with Transformer<a class="headerlink" href="#create-the-inferenceservice-with-transformer" title="Permanent link">¶</a></h3>
<p>Please use the <a href="torch_transformer.yaml">YAML file</a> to create the InferenceService, which adds the image transformer component with the docker image built from above.
<div class="highlight"><pre><span></span><code><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">serving.kserve.io/v1beta1</span>
<span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">InferenceService</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">torch-transfomer</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="w">  </span><span class="nt">predictor</span><span class="p">:</span>
<span class="w">    </span><span class="nt">triton</span><span class="p">:</span>
<span class="w">      </span><span class="nt">storageUri</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gs://kfserving-examples/models/torchscript</span>
<span class="w">      </span><span class="nt">runtimeVersion</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">20.10-py3</span>
<span class="w">      </span><span class="nt">env</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">OMP_NUM_THREADS</span>
<span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="s">"1"</span>
<span class="w">  </span><span class="nt">transformer</span><span class="p">:</span>
<span class="w">    </span><span class="nt">containers</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kfserving/image-transformer-v2:latest</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">kserve-container</span>
<span class="w">      </span><span class="nt">command</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">"python"</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">"-m"</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">"image_transformer_v2"</span>
<span class="w">      </span><span class="nt">args</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">--model_name</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cifar10</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">--protocol</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">v2</span>
</code></pre></div></p>
<div class="highlight"><pre><span></span><code>kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>torch_transformer.yaml
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>$<span class="w"> </span>inferenceservice.serving.kserve.io/torch-transfomer<span class="w"> </span>created
</code></pre></div>
</div>
<h3 id="run-a-prediction-with-curl_1">Run a prediction with curl<a class="headerlink" href="#run-a-prediction-with-curl_1" title="Permanent link">¶</a></h3>
<p>The transformer does not enforce a specific schema like predictor but the general recommendation is to send in as a list of object(dict):
<code>"instances": &lt;value&gt;|&lt;list-of-objects&gt;</code>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">"instances"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">"image_bytes"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">"b64"</span><span class="p">:</span><span class="w"> </span><span class="s2">"aW1hZ2UgYnl0ZXM="</span><span class="w"> </span><span class="p">},</span>
<span class="w">      </span><span class="nt">"caption"</span><span class="p">:</span><span class="w"> </span><span class="s2">"seaside"</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">"image_bytes"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">"b64"</span><span class="p">:</span><span class="w"> </span><span class="s2">"YXdlc29tZSBpbWFnZSBieXRlcw=="</span><span class="w"> </span><span class="p">},</span>
<span class="w">      </span><span class="nt">"caption"</span><span class="p">:</span><span class="w"> </span><span class="s2">"mountains"</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">]</span>
<span class="p">}</span>
</code></pre></div></p>
<div class="highlight"><pre><span></span><code><span class="c1"># download the input file</span>
curl<span class="w"> </span>-O<span class="w"> </span>https://raw.githubusercontent.com/kserve/kserve/master/docs/samples/v1beta1/triton/torchscript/image.json

<span class="nv">SERVICE_NAME</span><span class="o">=</span>torch-transfomer
<span class="nv">MODEL_NAME</span><span class="o">=</span>cifar10
<span class="nv">INPUT_PATH</span><span class="o">=</span>@./image.json

<span class="nv">SERVICE_HOSTNAME</span><span class="o">=</span><span class="k">$(</span>kubectl<span class="w"> </span>get<span class="w"> </span>inferenceservice<span class="w"> </span><span class="nv">$SERVICE_NAME</span><span class="w"> </span>-o<span class="w"> </span><span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.url}'</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>cut<span class="w"> </span>-d<span class="w"> </span><span class="s2">"/"</span><span class="w"> </span>-f<span class="w"> </span><span class="m">3</span><span class="k">)</span>

curl<span class="w"> </span>-v<span class="w"> </span>-H<span class="w"> </span><span class="s2">"Host: </span><span class="si">${</span><span class="nv">SERVICE_HOSTNAME</span><span class="si">}</span><span class="s2">"</span><span class="w"> </span>-H<span class="w"> </span><span class="s2">"Content-Type: application/json"</span><span class="w"> </span>http://<span class="si">${</span><span class="nv">INGRESS_HOST</span><span class="si">}</span>:<span class="si">${</span><span class="nv">INGRESS_PORT</span><span class="si">}</span>/v1/models/<span class="si">${</span><span class="nv">MODEL_NAME</span><span class="si">}</span>:predict<span class="w"> </span>-d<span class="w"> </span><span class="nv">$INPUT_PATH</span>
</code></pre></div>
<div class="admonition success">
<p class="admonition-title">Expected Output</p>
<div class="no-copy highlight"><pre><span></span><code>&gt;<span class="w"> </span>POST<span class="w"> </span>/v1/models/cifar10:predict<span class="w"> </span>HTTP/1.1
&gt;<span class="w"> </span>Host:<span class="w"> </span>torch-transformer.kserve-triton.example.com
&gt;<span class="w"> </span>User-Agent:<span class="w"> </span>curl/7.68.0
&gt;<span class="w"> </span>Accept:<span class="w"> </span>*/*
&gt;<span class="w"> </span>Content-Length:<span class="w"> </span><span class="m">3400</span>
&gt;<span class="w"> </span>Content-Type:<span class="w"> </span>application/x-www-form-urlencoded
&gt;<span class="w"> </span>Expect:<span class="w"> </span><span class="m">100</span>-continue
&gt;
*<span class="w"> </span>Mark<span class="w"> </span>bundle<span class="w"> </span>as<span class="w"> </span>not<span class="w"> </span>supporting<span class="w"> </span>multiuse
&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">100</span><span class="w"> </span>Continue
*<span class="w"> </span>We<span class="w"> </span>are<span class="w"> </span>completely<span class="w"> </span>uploaded<span class="w"> </span>and<span class="w"> </span>fine
*<span class="w"> </span>Mark<span class="w"> </span>bundle<span class="w"> </span>as<span class="w"> </span>not<span class="w"> </span>supporting<span class="w"> </span>multiuse
&lt;<span class="w"> </span>HTTP/1.1<span class="w"> </span><span class="m">200</span><span class="w"> </span>OK
&lt;<span class="w"> </span>content-length:<span class="w"> </span><span class="m">219</span>
&lt;<span class="w"> </span>content-type:<span class="w"> </span>application/json<span class="p">;</span><span class="w"> </span><span class="nv">charset</span><span class="o">=</span>UTF-8
&lt;<span class="w"> </span>date:<span class="w"> </span>Sat,<span class="w"> </span><span class="m">19</span><span class="w"> </span>Mar<span class="w"> </span><span class="m">2022</span><span class="w"> </span><span class="m">12</span>:15:54<span class="w"> </span>GMT
&lt;<span class="w"> </span>server:<span class="w"> </span>istio-envoy
&lt;<span class="w"> </span>x-envoy-upstream-service-time:<span class="w"> </span><span class="m">41</span>
&lt;
<span class="o">{</span><span class="s2">"OUTPUT__0"</span>:<span class="w"> </span><span class="o">[[</span>-2.0964810848236084,<span class="w"> </span>-0.137007474899292,<span class="w"> </span>-0.5095658302307129,<span class="w"> </span><span class="m">2</span>.795621395111084,<span class="w"> </span>-0.560547947883606,<span class="w"> </span><span class="m">1</span>.9934231042861938,<span class="w"> </span><span class="m">1</span>.1288189888000488,<span class="w"> </span>-<span class="w">    </span><span class="m">4043136835098267</span>,<span class="w"> </span><span class="m">0</span>.600488007068634,<span class="w"> </span>-2.1237082481384277<span class="o">]]}</span>%
</code></pre></div>
</div>
</article>
</div>
</div>
<a class="md-top md-icon" data-md-component="top" data-md-state="hidden" href="#">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path></svg>
            Back to top
          </a>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: ONNX" class="md-footer__link md-footer__link--prev" href="../../onnx/" rel="prev">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</div>
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Previous
              </span>
              ONNX
            </div>
</div>
</a>
<a aria-label="Next: Tensorflow" class="md-footer__link md-footer__link--next" href="../bert/" rel="next">
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Next
              </span>
              Tensorflow
            </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Copyright © 2021 The KServe Authors
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/kserve" rel="noopener" target="_blank" title="KServe Community on Github">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</a>
<a class="md-social__link" href="https://github.com/kserve/community/blob/main/README.md#questions-and-issues" rel="noopener" target="_blank" title="Join Slack">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.tracking", "navigation.tabs.sticky", "navigation.top"], "search": "../../../../assets/javascripts/workers/search.cefbb252.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": {"provider": "mike"}}</script>
<script src="../../../../assets/javascripts/bundle.a5f8ea78.min.js"></script>
<script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body>
</html>